{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOwsuGQQY9OL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN,\\\n",
    "Bidirectional,SpatialDropout1D,Activation, Dropout, BatchNormalization, GlobalAveragePooling1D, GRU\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from unidecode import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.random import seed\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler,SVMSMOTE\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../dados/Hackathon_Base_Treino_comdep.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../dados/Hackathon_Base_Teste.csv',sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbExternoManual = pd.read_excel('../dados/baseExterno/bdManual_dotzv001.xlsx', 'Planilha5',sep=';',index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "dbExterno = pd.read_csv('../dados/baseExterno/dbExternoV009.csv',sep=',',index_col=0)\n",
    "dbExterno.columns = ['DESCRIÇÃO PARCEIRO','CATEGORIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos = pd.read_csv('../envios/grupos.csv', index_col='Unnamed: 0')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cats_encoder = LabelEncoder()\n",
    "grupos['categoria_encoded'] = cats_encoder.fit_transform(grupos['CATEGORIA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['DESCRIÇÃO PARCEIRO','CATEGORIA','SUB-CATEGORIA','DEPARTAMENTO']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['DESCRIÇÃO PARCEIRO']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#stopwords = nltk.corpus.stopwords.words('portuguese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('\\[/(){}\\[\\]\\|@,;')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_-]')\n",
    "STOPWORDS = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS.add('c')\n",
    "STOPWORDS.add('n')\n",
    "STOPWORDS.add('d')\n",
    "STOPWORDS.add('+')\n",
    "STOPWORDS.add('com')\n",
    "STOPWORDS.add('sem')\n",
    "STOPWORDS.add('para')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def putCharBtw(x,letra,sep):\n",
    "    rex = re.compile('[0-9]'+letra)\n",
    "    if rex.search(x)==None:\n",
    "        return x\n",
    "    else:\n",
    "        inicio = (rex.search(x).start())+1\n",
    "        newString = x[:inicio]+sep+x[inicio:]\n",
    "        return newString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscaEreplace(text,term1, term2, wordreplaceTerm2):\n",
    "    if term1 in text:\n",
    "        if term2 in text:\n",
    "            #print(text,' '+term2+' ',' '+wordreplaceTerm2+' ')\n",
    "            text = text.replace(term2,wordreplaceTerm2)\n",
    "            \n",
    "    return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeWordBeforePosition(text,term1, term2, position):\n",
    "    pos = 0\n",
    "    for t in text.split():\n",
    "        pos=pos+1\n",
    "        if (t==term1) & (pos <= position):\n",
    "            text = text.replace(term1,term2)\n",
    "            #print(\"entrou\",text)\n",
    "            break\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeWordAfterPosition(text,term1, term2, position):\n",
    "    pos = 0\n",
    "    for t in text.split():\n",
    "        pos=pos+1\n",
    "        if (t==term1) & (pos <= position):\n",
    "            text = text.replace(term1,term2)\n",
    "            #print(\"entrou\",text)\n",
    "            break\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predTop3(dtbase, predicoes):\n",
    "    seq = 0\n",
    "    dtbase['top1'] = 1\n",
    "    dtbase['top2'] = 2\n",
    "    dtbase['top3'] = 3\n",
    "    \n",
    "    for predicao in predicoes:        \n",
    "        seq  +=1\n",
    "        \n",
    "        top3 = rankdata(predicao).argsort()[-3:][::-1]\n",
    "        categoria1 = grupos[grupos['categoria_encoded']==top3[0]]['CATEGORIA'].max()\n",
    "        categoria2 = grupos[grupos['categoria_encoded']==top3[1]]['CATEGORIA'].max()\n",
    "        categoria3 = grupos[grupos['categoria_encoded']==top3[2]]['CATEGORIA'].max()\n",
    "\n",
    "        dtbase.loc[dtbase[seq-1:seq].index,'top1'] = categoria1\n",
    "        dtbase.loc[dtbase[seq-1:seq].index,'top2'] = categoria2\n",
    "        dtbase.loc[dtbase[seq-1:seq].index,'top3'] = categoria3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceWord(text, antiga, nova):\n",
    "    text = [nova if t == antiga else t for t in text.split()]\n",
    "    return ' '.join(text)\n",
    "    #['corte' if t in 'cortess' else t for t in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = unidecode(text)\n",
    "    text = text.replace('+', ' + ')\n",
    "    text = text.replace('.', ' . ')\n",
    "    text = text.replace('.', ' ')\n",
    "    text = text.replace('-', ' ')\n",
    "    text = text.replace('+', ' ')\n",
    "    text = replaceWord(text,'d', ' ')\n",
    "    text = replaceWord(text, 'n', '')\n",
    "    text = replaceWord(text,'c', '')\n",
    "    text = replaceWord(text, 'pcte', 'pct')\n",
    "    text = replaceWord(text,'pt', 'pct')\n",
    "    text = text.replace(r'c/',' com ')\n",
    "    text = text.replace(r\"\\.c/\",' com ')\n",
    "    text = text.replace(r'-c/',' com ')\n",
    "    text = text.replace(' s/',' sem ')\n",
    "    text = text.replace(r'\\.s/',' sem ')\n",
    "    text = text.replace(r'-s/',' sem ')\n",
    "    text = text.replace(' p/',' para ')\n",
    "    text = text.replace(r'\\.p/',' para ')\n",
    "    text = text.replace(r'-p/',' para ')\n",
    "    text = putCharBtw(text,'ml',' ')\n",
    "    text = putCharBtw(text,'kg',' ')\n",
    "    text = putCharBtw(text,'g',' ')\n",
    "    text = putCharBtw(text,'gr',' ')\n",
    "    text = putCharBtw(text,'cm',' ')\n",
    "    text = putCharBtw(text,'l',' ')\n",
    "    text = putCharBtw(text,'mm',' ')\n",
    "    text = putCharBtw(text,'mt',' ')\n",
    "    text = putCharBtw(text,'un',' ')\n",
    "    text = text.replace('/',' / ')\n",
    "    text = text.replace('/','')\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    #text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    text = text.replace('  ',' ')\n",
    "    text = text.replace('  ',' ')\n",
    "    text = replaceWord(text,'c', '')\n",
    "    text = replaceWord(text,'com', '')\n",
    "    text = replaceWord(text,'de', '')\n",
    "    text = replaceWord(text,'sem', '')\n",
    "    text = replaceWord(text,'para', '')\n",
    "    text = replaceWord(text,'cortes', 'corte')\n",
    "    text = replaceWord(text,'pvc', 'past')\n",
    "    text = replaceWord(text,'rapadu', 'rapadura')\n",
    "    text = replaceWord(text,'melanina', 'melan')\n",
    "    text = replaceWord(text,'unid', 'un')\n",
    "    text = text.replace('mix berrys ', 'mix grao ')\n",
    "    text = text.replace(' louro cl', ' louro claro') #\n",
    "    text = 'bola natal' if 'bola natal' in text else text\n",
    "    text = replaceWord(text,'beefbone ', 'alim cao ')\n",
    "    text = text.replace('cera capilar', 'gel fix')\n",
    "    text = text.replace('cera p cab', 'gel fix')\n",
    "    text = buscaEreplace(text,' 2 l', 'refriger ', 'refrigerante ')\n",
    "    text = replaceWord(text,'refriger', 'refrigerador')\n",
    "    text = replaceWord(text,'dental', ' dent')\n",
    "    text = text.replace('humus de minhoca', 'adubo')\n",
    "    text = replaceWord(text,'frutas', 'fruta')\n",
    "    text = replaceWord(text,'carambola', 'carambola fruta')\n",
    "    text = text.replace('cre mao ', 'creme mao ')\n",
    "    text = replaceWord(text,'maos', ' mao ')\n",
    "    text = replaceWord(text,'organico', 'org')\n",
    "    text = replaceWord(text,'chedda', 'cheddar')\n",
    "    text = replaceWord(text,'caes', 'cao')\n",
    "    text = replaceWord(text,'integral', 'integ')\n",
    "    text = replaceWord(text,'congelada', 'cong')\n",
    "    text = replaceWord(text,'resfriado', 'resf')\n",
    "    text = replaceWord(text,'resfriada', 'resf')\n",
    "    text = replaceWord(text,'fresca', 'fresc')\n",
    "    text = replaceWord(text,'fresco', 'fresco')\n",
    "    text = replaceWord(text,'marinex', 'vidro')\n",
    "    text = replaceWord(text,'esfirra', 'esfiha')\n",
    "    text = text.replace('caf esfiha ', 'esfiha ')\n",
    "    text = text.replace('mousse charming', 'fixador')\n",
    "    text = replaceWord(text,'hamburguinho', 'hamb')\n",
    "    text = replaceWord(text,'kids', 'inf')\n",
    "    text = replaceWord(text,'garrafas', 'garrafa')\n",
    "    text = replaceWord(text,'cuticula', 'cutic')\n",
    "    text = text.replace('papel alum ', 'papel aluminio ')\n",
    "    text = replaceWord(text,'champignon', 'cogumelo champignon')\n",
    "    text = text.replace('cogumelo cogumelo champignon', 'cogumelo champignon')    \n",
    "    text = replaceWord(text,'automotiva', 'automotivo')\n",
    "    text = replaceWord(text,'polietileno', 'plast')\n",
    "    text = replaceWord(text,'suin', 'suino')\n",
    "    text = replaceWord(text,'suina', 'suino')\n",
    "    text = replaceWord(text,'plastico', 'plast')\n",
    "    text = text.replace('vinho espumante', 'espumante vinho')\n",
    "    text = replaceWord(text,'festa', 'fest')\n",
    "    text = replaceWord(text,'infantil', 'inf')\n",
    "    text = replaceWord(text,'tabl', 'tablete')\n",
    "    text = replaceWord(text,'tablet', 'tablete')\n",
    "    text = replaceWord(text,'dental', 'dent')\n",
    "    text = replaceWord(text,'desodorante ', 'desod')\n",
    "    text = replaceWord(text,'feminino', 'fem')\n",
    "    text = replaceWord(text,'multuso', 'multiuso')\n",
    "    text = replaceWord(text,'m-uso', 'multiuso')\n",
    "    text = replaceWord(text,'ativador ', 'ativ')\n",
    "    text = replaceWord(text,'bovino ', 'bov')\n",
    "    text = replaceWord(text,'baby', ' baby')\n",
    "    text = replaceWord(text,'brinquedo', 'brinq')\n",
    "    text = replaceWord(text,'madeira', 'mad')\n",
    "    text = replaceWord(text,'hidratante', 'hidrat ')\n",
    "    text = replaceWord(text,'limpeza', 'limp')\n",
    "    text = replaceWord(text,'iakon', 'yakon')\n",
    "    text = replaceWord(text,'pepininhos', 'pepino')\n",
    "    text = replaceWord(text,'pepininho', 'pepino')\n",
    "    text = replaceWord(text,'repelente', 'repel')\n",
    "    text = replaceWord(text,'verde', 'vde')\n",
    "    text = replaceWord(text,'bacalhau','bacal')\n",
    "    text = replaceWord(text,'liquido','liq')\n",
    "    text = buscaEreplace(text,'massa ', ' fr ', 'fresc ')\n",
    "    text = buscaEreplace(text,'pentear', 'creme ', 'cr ')\n",
    "    text = buscaEreplace(text,' dental', 'esc ', 'escova ')\n",
    "    text = buscaEreplace(text,' dent', 'esc ', 'escova ')\n",
    "    text = buscaEreplace(text,'escova ', 'dent', 'dental ')\n",
    "    text = text.replace('ed inf', ' escova dental inf ')\n",
    "    text = buscaEreplace(text,'saboneteira', 'inox ', '')\n",
    "    text = buscaEreplace(text,'lixeira', 'inox ', '')\n",
    "    text = buscaEreplace(text,' unha', 'inox ', '')\n",
    "    text = buscaEreplace(text,'pet 2 l', 'ref ', 'refrigerante ')\n",
    "    text = buscaEreplace(text,'peixe ', ' con', ' cong')\n",
    "    text = replaceWord(text,'cabelos', 'cab')\n",
    "    text = replaceWord(text,'cabelo', 'cab')\n",
    "    text = replaceWord(text,'esfirra', 'esfiha')\n",
    "    text = replaceWord(text,'esfirras', 'esfiha')\n",
    "    text = replaceWord(text,'crinca', 'infantil')\n",
    "    text = text.replace('sabonete ', 'sab ')\n",
    "    text = replaceWord(text,'cereal', 'cereal mat')\n",
    "    text = text.replace('cereal mat mat', 'cereal mat')\n",
    "    text = text.replace('aroma das indias', 'temp')\n",
    "    text = text.replace('bisc povilho', 'salg povilho')\n",
    "    text = text.replace('biscoito de povilho', 'salg povilho')\n",
    "    text = replaceWord(text,'facial', 'fac')\n",
    "    text = text.replace('barras energ', 'barra cereal')\n",
    "    text = replaceWord(text,'plasvale', 'plast')\n",
    "    text = replaceWord(text,'sabon', 'sab')\n",
    "    text = text.replace('kit cobre leito', 'cobre leito')\n",
    "    text = replaceWord(text,'xicaras', 'xicara')\n",
    "    text = text.replace('goma mascar', 'chiclete')\n",
    "    text = replaceWord(text,'pimenta ', 'pim ')\n",
    "    text = replaceWord(text,'pimen ', 'pim ')\n",
    "    text = replaceWord(text,'pvc ', 'plast ')\n",
    "    text = replaceWord(text,'espatulas', 'espatula')\n",
    "    text = replaceWord(text,'churrasco', 'churras')\n",
    "    text = text.replace('limp banheiro', 'limp banh')\n",
    "    text = replaceWord(text,'termica', 'term')\n",
    "    text = text.replace('pote vd', 'pote vidro')\n",
    "    text = text.replace('caneca vd', 'caneca vidro')\n",
    "    text = text.replace('prato fundo vd', 'prato fundo vidro')\n",
    "    text = text.replace('hot chilli', 'pimenta')\n",
    "    text = text.replace('sabon liq int', 'sab intimo ')\n",
    "    text = text.replace('sab liq int', 'sab intimo ')\n",
    "    text = text.replace('sab int', 'sab intimo ')\n",
    "    text = text.replace('sabonete liquido intimo ', 'sab intimo ')\n",
    "    text = text.replace('pre action', 'sup alim')\n",
    "    text = replaceWord(text,'grapettinho', 'refrigerante')\n",
    "    text = text.replace('ref tri cola', 'refrigerante cola ')\n",
    "    text = text.replace('mist prep liq cha', 'cha ')\n",
    "    text = replaceWord(text,'peix', 'peixe ')\n",
    "    text = text.replace('limpador limpeza pesada', 'limp pezada ')\n",
    "    text = replaceWord(text,'provolone', 'queijo provolone')\n",
    "    text = text.replace('queijo queijo provolone', 'queijo provolone ')\n",
    "    #text = replaceWord(text,'macarrao', 'mac')\n",
    "    text = replaceWord(text,'baby', 'inf')\n",
    "    text = text.replace('alimento passaro', 'alim passaro ')\n",
    "    text = replaceWord(text,'panet', 'panetone')\n",
    "    text = replaceWord(text,'pa higienica', 'pa hig')\n",
    "    text = text.replace('file fgo', 'file frango')\n",
    "    text = replaceWord(text,'masculino', 'masc')\n",
    "    text = replaceWord(text,'feminino', 'fem')\n",
    "    text = replaceWord(text,'corporal', 'corpo')\n",
    "    text = text.replace('cr leite', 'creme de leite')\n",
    "    text = replaceWord(text,'keldog', 'cao')\n",
    "    text = replaceWord(text,'barbea', 'cao')\n",
    "    text = replaceWord(text,'barber', 'cao')\n",
    "    text = replaceWord(text,'barbear', 'cao')\n",
    "    text = text.replace('cr barb', 'espuma barb')\n",
    "    text = replaceWord(text,'refrigerante', 'refrig')\n",
    "    text = buscaEreplace(text,'antartica', 'guarana', 'refrig guarana')\n",
    "    text = text.replace('refrig refrig guarana', 'refrig guarana')\n",
    "    text = replaceWord(text,'popcorn', 'pipoca')\n",
    "    text = text.replace('salg coxinha', 'coxinha')\n",
    "    text = text.replace('salg coxinhas', 'coxinha')\n",
    "    text = replaceWord(text,'macas', 'maca')\n",
    "    text = text.replace('limp lysoform', 'desinf lysoform')\n",
    "    text = buscaEreplace(text,'caneca ', ' cer ', ' ceram ')\n",
    "    text = text.replace('baguete com queijo', 'baguete')\n",
    "    text = text.replace('baguete queijo', 'baguete')\n",
    "    text = replaceWord(text,'livros', 'livro')\n",
    "    text = text.replace('temp sazon', 'caldo sazon')\n",
    "    text = replaceWord(text,'begonia', 'flor nat begonia')\n",
    "    text = text.replace('flor nat flor nat begonia', 'flor nat begonia')\n",
    "    text = replaceWord(text,'crocantissimo', 'bisc int')\n",
    "    text = replaceWord(text,'carrinho', 'carro')\n",
    "    text = replaceWord(text,'inseticida', 'inset')\n",
    "    text = replaceWord(text,'inseti', 'inset')\n",
    "    text = replaceWord(text,'sorrentinos', 'massa fr')\n",
    "    text = text.replace('folha file suculento maggi', 'temp maggi')\n",
    "    text = text.replace('amendoa laminada', 'amendoa casca')\n",
    "    text = text.replace('barra cer ', 'barra cereal ')\n",
    "    text = text.replace('supino banana', 'barra cereal supino banana')\n",
    "    text = text.replace('barra cereal barra cereal supino banana', 'barra cereal supino banana')\n",
    "    text = text.replace('pura nata cheddar', 'queijo cheddar pura nata')\n",
    "    text = text.replace('kids kids', 'inf')\n",
    "    text = text.replace('choc inf', 'choc')\n",
    "    text = replaceWord(text,'goiabinha', 'goiabada ')\n",
    "    text = replaceWord(text,'CarXparts', 'automotivo ')\n",
    "    text = replaceWord(text,'eberg', 'energetico ')\n",
    "    text = replaceWord(text,'geladinho', 'sorvete ')\n",
    "    text = replaceWord(text,'quibe', 'kibe')\n",
    "    text = replaceWord(text,'para', '')\n",
    "    text = replaceWord(text,'legumes', 'legume')\n",
    "    text = replaceWord(text,'cachorro', 'cao')\n",
    "    text = replaceWord(text,'caes', 'cao')\n",
    "    text = text.replace('mix leg ', 'mix legume ')\n",
    "    text = text.replace('alim p cao', 'alim cao ')\n",
    "    text = text.replace('biscoito cao', 'alim cao ')\n",
    "    text = text.replace('coxinha da asa fgo', 'coxinha asa frango ')\n",
    "    text = text.replace('coxinha asa fg', 'coxinha asa frango ')\n",
    "    text = text.replace('coxinha asa', 'coxinha asa frango ')\n",
    "    text = text.replace('coxinha frango cong', 'coxinha asa frango cong ')\n",
    "    text = text.replace('coxinha da asa', 'coxinha asa frango ')\n",
    "    text = text.replace('coxinha da asa fgo', 'coxinha asa frango ')\n",
    "    text = text.replace('palito fibras', 'barra cereal ')\n",
    "    text = text.replace('cozinha carnaroli', 'arroz carnaroli ')\n",
    "    text = buscaEreplace(text,'abas', 'intimus ', 'abs intimus ')\n",
    "    text = text.replace('abs abs intimus', 'abs intimus')\n",
    "    text = replaceWord(text,'graos', 'grao')\n",
    "    text = replaceWord(text,'bombocado', 'mist bolo bombocado')\n",
    "    text = text.replace('mist bolo mist bolo bombocado', 'mist bolo bombocado')\n",
    "    text = buscaEreplace(text,'palito', ' chur ', ' churras ')\n",
    "    text = text.replace('esteira sudare', 'sushi esteira sudare')\n",
    "    text = text.replace('escova profissional thermal', 'escova cab thermal')\n",
    "    text = replaceWord(text,'rosbife', 'rosbife bovino')\n",
    "    text = text.replace('rosbife rosbife bovino', 'rosbife bovino')\n",
    "    text = replaceWord(text,'termog', 'suplem termogenico')\n",
    "    text = replaceWord(text,'suplemento', 'suplem')\n",
    "    text = text.replace('suplem suplem termogenico', 'suplem termogenico')\n",
    "    text = replaceWord(text,'fosforos', 'fosforo')\n",
    "    text = replaceWord(text,'carxparts', 'automotivo')\n",
    "    text = text.replace('sab fac ', 'sab facial ')\n",
    "    text = text.replace('lenc fac ', 'lenco facial ')\n",
    "    text = text.replace('lenco fac ', 'lenco facial ')\n",
    "    text = buscaEreplace(text,'solar', ' fac ', ' facial ')\n",
    "    text = text.replace('mac ital ', 'mac ita ')\n",
    "    text = text.replace('massa ital ', 'mac ita ')\n",
    "    text = replaceWord(text,'organico ', 'org ')\n",
    "    text = replaceWord(text,'organic ', 'org ')\n",
    "    text = replaceWord(text,'organ ', 'org ')\n",
    "    text = text.replace('ext virg', 'extra virgem')\n",
    "    text = text.replace('beb energ', 'beb energetico')\n",
    "    text = replaceWord(text,'energet ', 'energetico ')\n",
    "    text = text.replace('suco nat', 'suco natural')\n",
    "    text = replaceWord(text,'caderneta ', 'caderno tilibra ')\n",
    "    text = buscaEreplace(text,'beijinho', 'doce ', 'doce fest beijinho ')\n",
    "    text = text.replace('presilha cab', 'prendedor cab')\n",
    "    text = text.replace('tilpapia ', 'tilapia ')\n",
    "    text = text.replace('bisc chimanguinho', 'salgadinho chimanguinho')\n",
    "    text = text.replace('bandeija ', 'bandeja ')\n",
    "    text = text.replace('bandejas ', 'bandeja ')\n",
    "    text = text.replace(' bandeija', ' bandeja')\n",
    "    text = text.replace(' bandejas', ' bandeja')\n",
    "    text = text.replace('lingua suino', 'linguica suino')\n",
    "    text = text.replace('asa do brasil', '') #testar\n",
    "    text = text.replace('asa do brasil', '')\n",
    "    text = replaceWord(text,'caramelo', 'caram')#CARAMELO FRUITTELLA\n",
    "    text = buscaEreplace(text,'fruittella', 'caram ', 'bala caram ')\n",
    "    text = text.replace('fruittella ', '')\n",
    "    text = buscaEreplace(text,'kg', 'barbecue', '')#M USO\n",
    "    text = text.replace('m uso ', 'multiuso ')\n",
    "    text = text.replace(' m uso', 'multiuso ')\n",
    "    text = text.replace(' gr ', ' g ')\n",
    "    text = text.replace('polpa celbola ', 'condim cebola ')\n",
    "    text = text.replace('cr pentear ', 'creme pentear ')\n",
    "    text = text.replace('desumidif ', 'desumidificador ')\n",
    "    text = text.replace('saco vasbras', 'saco lixo')\n",
    "    text = replaceWord(text,'minestrone', 'sopa legume minestrone')\n",
    "    text = text.replace('salg kibe', 'kibe')\n",
    "    text = replaceWord(text,'removed', 'removedor')\n",
    "    text = text.replace('esmalte defense', 'defense')\n",
    "    text = text.replace('esmal ', 'esmalte ')\n",
    "    text = text.replace('glu tai moto', 'condim glutamato')\n",
    "    text = text.replace('conj talher', 'cj talher')\n",
    "    text = text.replace('gojiberry', 'goji berry')\n",
    "    text = text.replace('suporte p coador', 'suporte coador')\n",
    "    text = text.replace('porta filtro', 'suporte coador')\n",
    "    text = replaceWord(text,'shampoo', 'sham')\n",
    "    text = replaceWord(text,'bebe', 'inf')\n",
    "    text = replaceWord(text,'torneiras', 'torneira')\n",
    "    text = text.replace('minas frescal', 'queijo minas frescal')\n",
    "    text = text.replace(' m uso ', 'multiuso')\n",
    "    text = text.replace(' m uso ', 'multiuso')\n",
    "    text = text.replace('tapete higienico', 'tapete hig')\n",
    "    text = text.replace(' m uso ', 'multiuso')\n",
    "    text = text.replace('dog', 'cao')\n",
    "    text = text.replace('palinetes', 'haste flex')\n",
    "    text = text.replace('hastes', 'haste')\n",
    "    text = text.replace('flexiveis', 'flexivel')\n",
    "    text = text.replace('haste flexivel', 'haste flex')\n",
    "    text = text.replace('massa delverde', 'mac ita delverde')\n",
    "    text = text.replace('triturador alho', 'amassador alho')\n",
    "    text = text.replace('mist gelatina', 'gelatina po')\n",
    "    text = text.replace('bolo chocolate', 'bolo choc')\n",
    "    text = text.replace('cachos', 'cacho')\n",
    "    text = replaceWord(text,'shopping', '')\n",
    "    text = buscaEreplace(text,'power', 'gelatina', 'gelatina capilar')\n",
    "    text = buscaEreplace(text,'gelatina', 'power', 'forca')\n",
    "    text = buscaEreplace(text,'org ', 'batata ', 'legume batata ')\n",
    "    text = text.replace('chicoria cheiro vde', 'chicoria')\n",
    "    text = buscaEreplace(text,'rucula', 'vde', '')\n",
    "    text = replaceWord(text,'kit', '')\n",
    "    text = replaceWord(text,'condicionante', 'mascara condicionante')\n",
    "    text = text.replace('mascara condicionante condicionante', 'mascara condicionante')\n",
    "    text = buscaEreplace(text,'vinagre', 'vinho', '')\n",
    "    text = replaceWord(text,'sacos', 'saco')\n",
    "    text = replaceWord(text,'molh', 'molho')\n",
    "    text = replaceWord(text,'pimen', 'pimenta')\n",
    "    text = replaceWord(text,'pimentas', 'pimenta')\n",
    "    text = replaceWord(text,'aliment', 'alim')\n",
    "    text = replaceWord(text,'r', '')\n",
    "    text = replaceWord(text,'mix', '')\n",
    "    text = replaceWord(text,'piment', 'pimenta')\n",
    "    text = replaceWord(text,'flores', 'flor')\n",
    "    text = replaceWord(text,'silvestres', 'silvestre')\n",
    "    text = replaceWord(text,'odorizador', 'purif ar')\n",
    "    text = replaceWord(text,'rasteirinha', 'sandalia')\n",
    "    text = replaceWord(text,'filhotes', 'filhote')\n",
    "    text = replaceWord(text,'gatos', 'gato')\n",
    "    text = replaceWord(text,'mamadeiras', 'mamadeira')\n",
    "    text = replaceWord(text,'porco', 'suino')\n",
    "    text = replaceWord(text,'bag', '')\n",
    "    text = replaceWord(text,'animais', 'animal')\n",
    "    text = replaceWord(text,'cuticulas', 'cuticula')\n",
    "    \n",
    "    text = text.replace('ferro passar', 'ferro vapor')\n",
    "    text = text.replace('massa peixe tikuwa', 'massa tikuwa')\n",
    "    text = text.replace('forno magico', 'forno magico')\n",
    "    text = text.replace('pe moca', 'pe moleque ')\n",
    "    text = text.replace('pe moca', 'pe moleque ')\n",
    "    text = text.replace('carro boneca', 'boneca ')\n",
    "    text = text.replace('carros', 'carro ')\n",
    "    text = text.replace('bonecos', 'boneco ')\n",
    "    text = text.replace('coco sec', 'coco ')\n",
    "    text = text.replace('gel acendedor', 'churras ')\n",
    "    text = text.replace('auto ', 'auto ')\n",
    "    text = text.replace('leite pentear ', 'cr pentear ')\n",
    "    text = text.replace('cre queijo', 'creme queijo ')\n",
    "    text = text.replace('cr queijo', 'creme pentear ')\n",
    "    text = text.replace('pres qjo', 'presunto queijo ')\n",
    "    text = text.replace('pastilha sanit ', 'desod sanit ')\n",
    "    text = text.replace('caldo sazon', 'temp sazon')\n",
    "    text = text.replace('caldo sazon', 'temp sazon')\n",
    "    text = text.replace('sha cond cao', 'shamp cond cao')\n",
    "    text = text.replace('limpz ', 'limp ')\n",
    "    text = text.replace('hot wings ', 'asa frango ')\n",
    "    text = text.replace('balalaika ', 'vodka ')\n",
    "    text = text.replace('queijo ricota ', 'ricota ')\n",
    "    text = text.replace('fresco cong ', 'fresco ') #\n",
    "    text = text.replace('bloco odorizante ', 'odorizante ')\n",
    "    text = text.replace('figo seco ', 'fruta figo ')\n",
    "    text = text.replace('alicate cut', 'alicate cuticula unha')\n",
    "    \n",
    "    \n",
    "    \n",
    "    text = buscaEreplace(text,'pinho', 'pastilha ', 'desod sanit')    \n",
    "    text = buscaEreplace(text,'presunto', 'rondelli', 'sanduiche rondelli')\n",
    "    text = buscaEreplace(text,'pres ', 'sand', 'sanduiche')\n",
    "    text = buscaEreplace(text,'sanduiche ', 'pres', 'presunto')\n",
    "    text = buscaEreplace(text,'escova ', 'banh ', 'banho ')\n",
    "    text = buscaEreplace(text,'margarina ', 'cap ', ' ')\n",
    "    text = buscaEreplace(text,'bolo ', 'leite cond', ' ')\n",
    "    text = buscaEreplace(text,'bolo ', 'leite cond', ' ')\n",
    "    text = buscaEreplace(text,'pimenta ', 'biq ', 'biquinho ')\n",
    "    text = buscaEreplace(text,'vela', 'pote vidro', '')\n",
    "    text = buscaEreplace(text,'nectar', 'mel ', 'mel silvestre')\n",
    "    text = buscaEreplace(text,'limo', 'limp banh', '')\n",
    "    text = buscaEreplace(text,'vodka', 'beb alc', '')\n",
    "    text = buscaEreplace(text,'suino', 'fresco', 'resf')#fresco cong\n",
    "    text = buscaEreplace(text,'pom pom', 'sab', 'sab inf')\n",
    "    \n",
    "    \n",
    "    text = text.replace('  ',' ')\n",
    "    text = text.replace('  ',' ')\n",
    "    text = text.replace('  ',' ')\n",
    "    #    text = re.sub(r'\\W+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosFull = pd.concat([train[['DESCRIÇÃO PARCEIRO','CATEGORIA','SUB-CATEGORIA']],\n",
    "                       dbExterno[['DESCRIÇÃO PARCEIRO','CATEGORIA']],\n",
    "                       dbExternoManual[['DESCRIÇÃO PARCEIRO','CATEGORIA']],\n",
    "                       test[['DESCRIÇÃO PARCEIRO']]], ignore_index=True, sort=False)\n",
    "dadosFull['descricao'] = dadosFull['DESCRIÇÃO PARCEIRO'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dadosFull[(dadosFull['descricao'].str.contains('milho vde'))]['descricao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dadosFull[(dadosFull['descricao'].str.contains('hortela'))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosFull[ (dadosFull['CATEGORIA']=='DOCE FESTA')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizerDotz.texts_to_sequences(\"ed inf oral b stages 1 4 24 meses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dadosFull[11131:11132]['descricao'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [13504,21484,21441,19480,693,9397,7166,5366,18948,10286,10286,11435,18623,12209,\n",
    "        8809,13279,2484,6578,90,5391,12674,18513,8744,13282,9653,3476,8815,\n",
    "       8815, 21920, 17272,541,2678,5822,17175,4086,13383,10271,19019,13383,\n",
    "       20943,2290,20943,20233,1804,11322,14309,11322,8181,1676,15275,\n",
    "       13665,12618,18697,9249,4467,12164]\n",
    "pd.options.display.max_rows = 200\n",
    "#dadosFull.loc[list].head(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosFull.drop([13504,21484,21441,19480,693,9397,7166,5366,18948,10286,10286,11435,18623,12209,\n",
    "        8809,13279,2484,6578,90,5391,12674,18513,8744,13282,9653,3476,8815,\n",
    "       8815, 21920, 17272,541,2678,5822,17175,4086,13383,10271,19019,13383,\n",
    "       20943,2290,20943,20233,1804,11322,14309,11322,8181,1676,15275,\n",
    "       13665,12618,18697,9249,4467,12164], axis=0, inplace=True)\n",
    "\n",
    "dadosFull.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizerDotz = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True,split=' ') \n",
    "tokenizerDotz.fit_on_texts(dadosFull['descricao'].values)\n",
    "word_index = tokenizerDotz.word_index \n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = len(word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = dadosFull[~dadosFull['CATEGORIA'].isnull()].copy()\n",
    "#trainX = trainX[:31442].copy()\n",
    "#X_test1ext = dadosFull[31442:].copy()\n",
    "trainY = dadosFull[~dadosFull['CATEGORIA'].isnull()]['CATEGORIA']\n",
    "#trainY = trainY[:31442].copy()\n",
    "#Y_test1ext = dadosFull[31442:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainAll = trainX.copy()\n",
    "#trainAll['CATEGORIA'] = trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cattrain_encoder = LabelEncoder()\n",
    "#trainAll['subcat_encode'] = cats_encoder.fit_transform(trainAll['CATEGORIA'])\n",
    "#categorias = trainY.value_counts()\n",
    "#reslist = []\n",
    "#for index, qtdreg in categorias.iteritems():\n",
    "#    if qtdreg < 100:\n",
    "#        reslist.append(100)\n",
    "#    else: \n",
    "#        reslist.append(qtdreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainAll['CATEGORIA'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reslist = {}\n",
    "for index, subcat_encode in trainAll['subcat_encode'].iteritems():\n",
    "    categoria = trainAll.loc[index]['CATEGORIA']\n",
    "    reslist[categoria] = \\\n",
    "    20 if trainAll[(trainAll['CATEGORIA']==categoria)]['CATEGORIA'].count() < 20 \\\n",
    "    else trainAll[(trainAll['CATEGORIA']==categoria)]['CATEGORIA'].count() \n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy=reslist)\n",
    "trainX, trainY = ros.fit_resample(trainAll, \n",
    "                                  trainAll[['CATEGORIA']])#sampling_strategy= 'minority'SVMSMOTE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling_strategy= 'minority'SVMSMOTE\n",
    "max([len(x) for x in trainX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(trainX,trainY, \n",
    "                                                        test_size = 0.0000001, \n",
    "                                                        random_state = 1215)##54,154,stratify=trainY\n",
    "print(X_train1.shape,Y_train1.shape) \n",
    "print(X_test1.shape,Y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train1[~X_train1['CATEGORIA'].isnull()]['descricao']\n",
    "X_test = X_test1[~X_test1['CATEGORIA'].isnull()]['descricao']\n",
    "#X_test1ext = X_test1ext[~X_test1ext['CATEGORIA'].isnull()]['descricao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizerDotz.texts_to_sequences(X_train.values)\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = max([len(x) for x in trainX])\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "print('Shape of data tensor:', X_train.shape, 'MAX_SEQUENCE_LENGTH', MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizerDotz.texts_to_sequences(X_test.values)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "print('Shape of data tensor:', X_test.shape)\n",
    "\n",
    "#X_test1ext = tokenizerDotz.texts_to_sequences(X_test1ext.values)\n",
    "#X_test1ext = pad_sequences(X_test1ext, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "#print('Shape of data tensor:', X_test1ext.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train1 = pd.get_dummies(Y_train1).values\n",
    "Y_test1 = pd.get_dummies(Y_test1).values\n",
    "print('Shape of label tensor:', Y_train1.shape)\n",
    "print('Shape of label tensor:', Y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ros = SVMSMOTE(random_state=42, sampling_strategy='minority')\n",
    "#X_res, y_res = ros.fit_resample(X_train, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(trainY),\n",
    "                                                 trainY)\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "#lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#    initial_learning_rate=1e-2,\n",
    "#    decay_steps=10000,\n",
    "#    decay_rate=0.9)\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 322\n",
    "batch_size = 64\n",
    "#seed_value = 14\n",
    "#seed(seed_value)\n",
    "#tf.random.set_seed(seed_value)\n",
    "#np.random.seed(seed_value)\n",
    "#tf.set_seed = seed_value\n",
    "#os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "#with tf.device('/CPU:0'):\n",
    "#with tf.device('/CPU:0'):\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "#model.add(Bidirectional(LSTM(322)))#,dropout=0.2,return_sequences=True\n",
    "#model.add(Bidirectional(LSTM(322)))\n",
    "model.add(GRU(322))#\n",
    "#model.add(SimpleRNN(512))\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1,seed=seed_value))\n",
    "model.add(Dense(322))#Y_train1.shape[1]\n",
    "model.add(BatchNormalization(axis=1, momentum=0.8)) #axis=1, momentum=0.08\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(Y_train1.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "history = model.fit(X_train, Y_train1, epochs=epochs, \n",
    "                    batch_size=batch_size,validation_split=0.07,#class_weight=class_weights,# shuffle=False,validation_batch_size=batch_size,\n",
    "                    callbacks=[EarlyStopping(monitor='accuracy', patience=3, \n",
    "                                             min_delta=0.0001,restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "history = model.fit(X_train, Y_train1, epochs=epochs, \n",
    "                    batch_size=batch_size,validation_split=0.08,#class_weight=class_weights,# shuffle=False,validation_batch_size=batch_size,\n",
    "                    callbacks=[EarlyStopping(monitor='accuracy', patience=1, \n",
    "                                             min_delta=0.0001,restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISE DE RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../modelos/DotzV017-CategoriaV015-2331')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('../modelos/DotzV017-tensorFlowNLPMulticlass-CategoriaV010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GERACAO DO ENVIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['descricao'] = test['DESCRIÇÃO PARCEIRO'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tokenizerDotz.texts_to_sequences(test['descricao'].values)\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "predicoes = model.predict(padded)\n",
    "predicted = np.argmax(model.predict(padded), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnvio = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnvio['categoria_encoded'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTop3(testEnvio,predicoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnvio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnvio.to_csv('../envios/preenvio/cat_envioTesteV042_2331.csv', index_label='0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Course 3 - Week 4 - Lesson 1 - Notebook.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
